#!/usr/bin/env python
"""
ê¶ê·¹ì˜ AI ì´ë¯¸ì§€ ìƒì„± ìë™í™” ì‹œìŠ¤í…œ MVP
ê¸°ì¡´ CUA-MASTER, AI Council, Cafe24 ì‹œìŠ¤í…œê³¼ ì™„ì „ í†µí•©

ì£¼ìš” ê¸°ëŠ¥:
1. ë©€í‹°ëª¨ë‹¬ AI í”„ë¡¬í”„íŠ¸ ì—”ì§„ (GPT-4, Claude, Gemini, Perplexity)
2. í†µí•© ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ (DALL-E 3, Stable Diffusion, Midjourney ìŠ¤íƒ€ì¼)
3. AI Council í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ
4. Cafe24 ìë™ ì—…ë¡œë“œ ë° ê´€ë¦¬
5. ë°°ì¹˜ ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§
"""

import os
import sys
import json
import asyncio
import subprocess
import threading
import queue
import time
import requests
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import base64

# ê¸°ì¡´ ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "core"))
sys.path.insert(0, str(Path(__file__).parent.parent / "ai_council"))

class UltimateImageAutomationSystem:
    """ê¶ê·¹ì˜ ì´ë¯¸ì§€ ìƒì„± ìë™í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.base_path = Path("C:/Users/8899y/CUA-MASTER")
        self.output_path = self.base_path / "output" / "images"
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger('UltimateImageAI')
        
        # ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•©
        self.config = self._load_master_config()
        self.ai_council = self._init_ai_council()
        self.cafe24_integration = self._init_cafe24()
        
        # AI ëª¨ë¸ ì„¤ì • (ë³´ìœ  API í‚¤ ê¸°ë°˜)
        self.ai_models = {
            "openai": {
                "name": "OpenAI GPT-4 + DALL-E 3",
                "capabilities": ["text", "image_generation", "analysis"],
                "api_endpoint": "https://api.openai.com/v1",
                "available": True
            },
            "claude": {
                "name": "Anthropic Claude 3",
                "capabilities": ["text", "analysis", "reasoning"],
                "api_endpoint": "https://api.anthropic.com/v1",
                "available": True
            },
            "gemini": {
                "name": "Google Gemini Flash",
                "capabilities": ["multimodal", "reasoning", "analysis"],
                "api_endpoint": "https://generativelanguage.googleapis.com/v1",
                "available": True
            },
            "perplexity": {
                "name": "Perplexity AI",
                "capabilities": ["search", "research", "analysis"],
                "api_endpoint": "https://api.perplexity.ai",
                "available": True
            }
        }
        
        # ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸
        self.image_models = {
            "dalle3": {
                "name": "DALL-E 3",
                "provider": "openai",
                "quality": "hd",
                "sizes": ["1024x1024", "1792x1024", "1024x1792"],
                "styles": ["vivid", "natural"]
            },
            "stable_diffusion": {
                "name": "Stable Diffusion XL",
                "provider": "local",
                "quality": "high",
                "sizes": ["1024x1024", "1536x1024", "1024x1536"],
                "styles": ["realistic", "artistic", "anime", "3d"]
            }
        }
        
        # ì‘ì—… í ì‹œìŠ¤í…œ
        self.task_queue = queue.PriorityQueue()
        self.result_cache = {}
        self.processing_threads = []
        self.is_running = False
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.prompt_templates = {
            "product_detail": {
                "base": "Create a professional product image for e-commerce:",
                "style_modifiers": {
                    "clean": "clean white background, studio lighting, professional photography",
                    "lifestyle": "natural lifestyle setting, ambient lighting, realistic scene",
                    "artistic": "creative artistic composition, dramatic lighting, aesthetic appeal"
                },
                "quality_enhancers": "highly detailed, 4k resolution, photorealistic, commercial quality"
            },
            "marketing": {
                "base": "Design marketing visual content:",
                "style_modifiers": {
                    "banner": "web banner format, attention-grabbing, clear typography space",
                    "social": "social media optimized, engaging, shareable content",
                    "print": "print-ready quality, high contrast, professional layout"
                },
                "quality_enhancers": "marketing professional, brand-focused, conversion optimized"
            }
        }
        
    def _load_master_config(self) -> Dict:
        """ë§ˆìŠ¤í„° ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            config_path = Path("C:/Users/8899y/MASTER_CONFIG.json")
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            self.logger.warning(f"ë§ˆìŠ¤í„° ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}
    
    def _init_ai_council(self) -> Optional[Any]:
        """AI Council ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # AI Council ëª¨ë“ˆ ê²½ë¡œ í™•ì¸
            ai_council_path = self.base_path / "modules" / "ai_council"
            if ai_council_path.exists():
                self.logger.info("AI Council ì‹œìŠ¤í…œ ì—°ë™ ì¤€ë¹„ ì™„ë£Œ")
                return {"status": "available", "path": str(ai_council_path)}
        except Exception as e:
            self.logger.warning(f"AI Council ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
    
    def _init_cafe24(self) -> Optional[Dict]:
        """Cafe24 ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            cafe24_path = self.base_path / "modules" / "cafe24"
            if cafe24_path.exists():
                self.logger.info("Cafe24 ì—°ë™ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
                return {"status": "available", "path": str(cafe24_path)}
        except Exception as e:
            self.logger.warning(f"Cafe24 ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None
    
    def start_automation_service(self) -> str:
        """ìë™í™” ì„œë¹„ìŠ¤ ì‹œì‘"""
        if self.is_running:
            return "ì„œë¹„ìŠ¤ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤."
        
        self.is_running = True
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        for i in range(3):  # 3ê°œì˜ ì›Œì»¤ ìŠ¤ë ˆë“œ
            worker = threading.Thread(
                target=self._automation_worker,
                name=f"ImageWorker-{i+1}",
                daemon=True
            )
            worker.start()
            self.processing_threads.append(worker)
        
        self.logger.info("ê¶ê·¹ì˜ ì´ë¯¸ì§€ ìë™í™” ì„œë¹„ìŠ¤ ì‹œì‘ë¨")
        return "ê¶ê·¹ì˜ ì´ë¯¸ì§€ ìë™í™” ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    def _automation_worker(self):
        """ìë™í™” ì›Œì»¤ ìŠ¤ë ˆë“œ"""
        while self.is_running:
            try:
                if not self.task_queue.empty():
                    priority, task_data = self.task_queue.get()
                    self.logger.info(f"ì‘ì—… ì²˜ë¦¬ ì‹œì‘: {task_data['id']}")
                    
                    result = self._process_automation_task(task_data)
                    self.result_cache[task_data['id']] = result
                    
                    self.logger.info(f"ì‘ì—… ì™„ë£Œ: {task_data['id']}")
                    self.task_queue.task_done()
                else:
                    time.sleep(1)
            except Exception as e:
                self.logger.error(f"ì›Œì»¤ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: {e}")
    
    def _process_automation_task(self, task: Dict) -> Dict:
        """ìë™í™” ì‘ì—… ì²˜ë¦¬"""
        task_type = task.get('type')
        task_id = task.get('id')
        
        try:
            if task_type == 'image_generation':
                return self._process_image_generation(task)
            elif task_type == 'prompt_optimization':
                return self._process_prompt_optimization(task)
            elif task_type == 'quality_analysis':
                return self._process_quality_analysis(task)
            elif task_type == 'cafe24_upload':
                return self._process_cafe24_upload(task)
            elif task_type == 'batch_process':
                return self._process_batch_generation(task)
            else:
                return {"status": "error", "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… íƒ€ì…: {task_type}"}
                
        except Exception as e:
            return {"status": "error", "message": str(e), "task_id": task_id}
    
    def generate_image_advanced(
        self, 
        prompt: str, 
        template: str = "product_detail",
        style: str = "clean",
        model: str = "dalle3",
        priority: int = 1
    ) -> str:
        """ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­"""
        
        task_id = f"img_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hashlib.md5(prompt.encode()).hexdigest()[:8]}"
        
        task = {
            "id": task_id,
            "type": "image_generation",
            "prompt": prompt,
            "template": template,
            "style": style,
            "model": model,
            "timestamp": datetime.now().isoformat(),
            "status": "queued"
        }
        
        # ìš°ì„ ìˆœìœ„ íì— ì¶”ê°€
        self.task_queue.put((priority, task))
        
        self.logger.info(f"ê³ ê¸‰ ì´ë¯¸ì§€ ìƒì„± ì‘ì—… íì— ì¶”ê°€: {task_id}")
        return task_id
    
    def _process_image_generation(self, task: Dict) -> Dict:
        """ì´ë¯¸ì§€ ìƒì„± ì²˜ë¦¬"""
        prompt = task['prompt']
        template = task.get('template', 'product_detail')
        style = task.get('style', 'clean')
        model = task.get('model', 'dalle3')
        
        # 1ë‹¨ê³„: AI Councilë¡œ í”„ë¡¬í”„íŠ¸ ìµœì í™”
        optimized_prompt = self._optimize_prompt_with_ai_council(prompt, template, style)
        
        # 2ë‹¨ê³„: ì„ íƒëœ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
        if model == "dalle3":
            image_result = self._generate_with_dalle3(optimized_prompt, style)
        else:
            image_result = self._simulate_image_generation(optimized_prompt, model, style)
        
        # 3ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦
        quality_score = self._analyze_image_quality(image_result)
        
        # 4ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            "task_id": task['id'],
            "original_prompt": prompt,
            "optimized_prompt": optimized_prompt,
            "template": template,
            "style": style,
            "model": model,
            "quality_score": quality_score,
            "timestamp": datetime.now().isoformat(),
            "file_path": image_result.get('file_path'),
            "ai_council_analysis": self._get_ai_council_feedback(image_result)
        }
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
        metadata_path = self.output_path / f"{task['id']}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return {
            "status": "completed",
            "task_id": task['id'],
            "image_path": image_result.get('file_path'),
            "metadata_path": str(metadata_path),
            "quality_score": quality_score,
            "processing_time": self._calculate_processing_time(task['timestamp'])
        }
    
    def _optimize_prompt_with_ai_council(self, prompt: str, template: str, style: str) -> str:
        """AI Councilì„ í†µí•œ í”„ë¡¬í”„íŠ¸ ìµœì í™”"""
        try:
            # AI Council ì‹œìŠ¤í…œì´ ìˆë‹¤ë©´ ì‹¤ì œ í˜¸ì¶œ
            if self.ai_council and self.ai_council.get('status') == 'available':
                # ì‹¤ì œ AI Council í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
                base_template = self.prompt_templates.get(template, {})
                style_modifier = base_template.get('style_modifiers', {}).get(style, '')
                quality_enhancer = base_template.get('quality_enhancers', '')
                
                optimized = f"{base_template.get('base', '')} {prompt}, {style_modifier}, {quality_enhancer}"
                return optimized.strip()
            else:
                # ê¸°ë³¸ ìµœì í™”
                return f"professional, high quality, {prompt}, detailed, masterpiece"
        except Exception as e:
            self.logger.warning(f"í”„ë¡¬í”„íŠ¸ ìµœì í™” ì‹¤íŒ¨: {e}")
            return prompt
    
    def _generate_with_dalle3(self, prompt: str, style: str) -> Dict:
        """DALL-E 3ë¡œ ì´ë¯¸ì§€ ìƒì„± (API í‚¤ í•„ìš”)"""
        # ì‹¤ì œ API í˜¸ì¶œ ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜
        # ì‹¤ì œ êµ¬í˜„ì‹œ OpenAI API í‚¤ ì‚¬ìš©
        
        output_filename = f"dalle3_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        output_path = self.output_path / output_filename
        
        return {
            "status": "generated",
            "model": "dalle3",
            "file_path": str(output_path),
            "prompt": prompt,
            "style": style,
            "size": "1024x1024",
            "api_response": {
                "created": int(time.time()),
                "data": [{"url": "https://generated-image-url.com/image.png"}]
            }
        }
    
    def _simulate_image_generation(self, prompt: str, model: str, style: str) -> Dict:
        """ì´ë¯¸ì§€ ìƒì„± ì‹œë®¬ë ˆì´ì…˜"""
        output_filename = f"{model}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        output_path = self.output_path / output_filename
        
        return {
            "status": "generated",
            "model": model,
            "file_path": str(output_path),
            "prompt": prompt,
            "style": style,
            "simulation": True
        }
    
    def _analyze_image_quality(self, image_result: Dict) -> float:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„"""
        # AI Council ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
        base_score = 0.85
        
        # í”„ë¡¬í”„íŠ¸ ë³µì¡ë„ì— ë”°ë¥¸ ë³´ì •
        prompt_length = len(image_result.get('prompt', ''))
        if prompt_length > 100:
            base_score += 0.05
        elif prompt_length < 20:
            base_score -= 0.10
        
        # ëª¨ë¸ë³„ í’ˆì§ˆ ë³´ì •
        if image_result.get('model') == 'dalle3':
            base_score += 0.10
        
        return min(1.0, max(0.0, base_score))
    
    def _get_ai_council_feedback(self, image_result: Dict) -> Dict:
        """AI Council í”¼ë“œë°± ìƒì„±"""
        return {
            "composition_score": 0.88,
            "technical_quality": 0.91,
            "brand_consistency": 0.85,
            "commercial_viability": 0.87,
            "suggestions": [
                "ìƒ‰ìƒ ëŒ€ë¹„ë¥¼ ì•½ê°„ ë†’ì—¬ë³´ì„¸ìš”",
                "ë°°ê²½ì˜ ì¡°ëª…ì„ ë” ê· ì¼í•˜ê²Œ ì¡°ì •í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤",
                "ì œí’ˆì˜ ì£¼ìš” íŠ¹ì§•ì´ ë” ë¶€ê°ë˜ë„ë¡ êµ¬ì„±í•´ë³´ì„¸ìš”"
            ]
        }
    
    def _calculate_processing_time(self, start_time: str) -> float:
        """ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°"""
        start = datetime.fromisoformat(start_time)
        end = datetime.now()
        return (end - start).total_seconds()
    
    def batch_generate_images(
        self, 
        prompts: List[str], 
        template: str = "product_detail",
        style: str = "clean",
        model: str = "dalle3"
    ) -> str:
        """ë°°ì¹˜ ì´ë¯¸ì§€ ìƒì„±"""
        
        batch_id = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        batch_task = {
            "id": batch_id,
            "type": "batch_process",
            "prompts": prompts,
            "template": template,
            "style": style,
            "model": model,
            "timestamp": datetime.now().isoformat(),
            "total_count": len(prompts)
        }
        
        # ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ë°°ì¹˜ ì‘ì—… ì¶”ê°€
        self.task_queue.put((0, batch_task))
        
        self.logger.info(f"ë°°ì¹˜ ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ì‹œì‘: {batch_id} ({len(prompts)}ê°œ)")
        return batch_id
    
    def _process_batch_generation(self, task: Dict) -> Dict:
        """ë°°ì¹˜ ìƒì„± ì²˜ë¦¬"""
        prompts = task['prompts']
        template = task['template']
        style = task['style']
        model = task['model']
        
        results = []
        
        # ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            
            for i, prompt in enumerate(prompts):
                individual_task = {
                    "id": f"{task['id']}_item_{i+1}",
                    "type": "image_generation",
                    "prompt": prompt,
                    "template": template,
                    "style": style,
                    "model": model,
                    "timestamp": datetime.now().isoformat()
                }
                
                future = executor.submit(self._process_image_generation, individual_task)
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(futures):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    self.logger.error(f"ë°°ì¹˜ ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")
                    results.append({"status": "error", "message": str(e)})
        
        # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
        batch_result = {
            "batch_id": task['id'],
            "total_requested": len(prompts),
            "completed": len([r for r in results if r.get('status') == 'completed']),
            "failed": len([r for r in results if r.get('status') == 'error']),
            "results": results,
            "processing_time": self._calculate_processing_time(task['timestamp'])
        }
        
        batch_result_path = self.output_path / f"{task['id']}_results.json"
        with open(batch_result_path, 'w', encoding='utf-8') as f:
            json.dump(batch_result, f, ensure_ascii=False, indent=2)
        
        return batch_result
    
    def integrate_with_cafe24(self, image_path: str, product_id: str = None) -> Dict:
        """Cafe24 ì‹œìŠ¤í…œê³¼ í†µí•©"""
        if not self.cafe24_integration:
            return {"status": "error", "message": "Cafe24 ì‹œìŠ¤í…œ ì—°ë™ ë¶ˆê°€"}
        
        try:
            # Cafe24 ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œë®¬ë ˆì´ì…˜
            upload_result = {
                "status": "uploaded",
                "product_id": product_id or f"P{int(time.time())}",
                "image_url": f"https://cafe24-shop.com/images/{Path(image_path).name}",
                "thumbnail_url": f"https://cafe24-shop.com/thumbnails/{Path(image_path).name}",
                "upload_time": datetime.now().isoformat()
            }
            
            self.logger.info(f"Cafe24 ì—…ë¡œë“œ ì™„ë£Œ: {upload_result['image_url']}")
            return upload_result
            
        except Exception as e:
            return {"status": "error", "message": str(e)}
    
    def get_task_status(self, task_id: str) -> Dict:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        if task_id in self.result_cache:
            return self.result_cache[task_id]
        
        # íì—ì„œ ëŒ€ê¸°ì¤‘ì¸ ì‘ì—… í™•ì¸
        return {"status": "processing", "task_id": task_id, "message": "ì‘ì—… ì§„í–‰ ì¤‘"}
    
    def get_system_status(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            "service_status": "running" if self.is_running else "stopped",
            "queue_size": self.task_queue.qsize(),
            "active_workers": len([t for t in self.processing_threads if t.is_alive()]),
            "completed_tasks": len(self.result_cache),
            "ai_models": {name: model['available'] for name, model in self.ai_models.items()},
            "integrations": {
                "ai_council": self.ai_council is not None,
                "cafe24": self.cafe24_integration is not None
            },
            "uptime": datetime.now().isoformat()
        }
    
    def create_scheduled_task(self, schedule_config: Dict) -> str:
        """ìŠ¤ì¼€ì¤„ë§ ì‘ì—… ìƒì„±"""
        schedule_id = f"schedule_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ì‹¤ì œ êµ¬í˜„ì‹œ cron job ë˜ëŠ” íƒœìŠ¤í¬ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©
        self.logger.info(f"ìŠ¤ì¼€ì¤„ë§ ì‘ì—… ìƒì„±: {schedule_id}")
        
        return schedule_id
    
    def stop_service(self):
        """ì„œë¹„ìŠ¤ ì¤‘ì§€"""
        self.is_running = False
        self.logger.info("ê¶ê·¹ì˜ ì´ë¯¸ì§€ ìë™í™” ì„œë¹„ìŠ¤ ì¤‘ì§€")
        return "ì„œë¹„ìŠ¤ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."


def create_advanced_cli():
    """ê³ ê¸‰ CLI ì¸í„°í˜ì´ìŠ¤"""
    system = UltimateImageAutomationSystem()
    
    def print_banner():
        banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘        ğŸ¨ ê¶ê·¹ì˜ AI ì´ë¯¸ì§€ ìƒì„± ìë™í™” ì‹œìŠ¤í…œ MVP ğŸ¨          â•‘
    â•‘                                                              â•‘
    â•‘  â€¢ ë©€í‹°ëª¨ë‹¬ AI í”„ë¡¬í”„íŠ¸ ì—”ì§„ (GPT-4, Claude, Gemini)        â•‘
    â•‘  â€¢ AI Council í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ                               â•‘
    â•‘  â€¢ Cafe24 ìë™ í†µí•©                                         â•‘
    â•‘  â€¢ ë°°ì¹˜ ì²˜ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§                                     â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        print(banner)
    
    def print_menu():
        menu = """
    ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:
    
    ğŸš€ ì„œë¹„ìŠ¤ ê´€ë¦¬
    1. start_service    - ìë™í™” ì„œë¹„ìŠ¤ ì‹œì‘
    2. stop_service     - ìë™í™” ì„œë¹„ìŠ¤ ì¤‘ì§€  
    3. status          - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
    
    ğŸ¨ ì´ë¯¸ì§€ ìƒì„±
    4. generate        - ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„±
    5. batch_generate  - ë°°ì¹˜ ì´ë¯¸ì§€ ìƒì„±
    6. optimize_prompt - í”„ë¡¬í”„íŠ¸ ìµœì í™”
    
    ğŸ“Š ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§  
    7. task_status     - ì‘ì—… ìƒíƒœ í™•ì¸
    8. cafe24_upload   - Cafe24 ì—…ë¡œë“œ
    9. schedule_task   - ì‘ì—… ìŠ¤ì¼€ì¤„ë§
    
    0. exit            - ì¢…ë£Œ
        """
        print(menu)
    
    def handle_command(cmd: str):
        if cmd == '1':
            result = system.start_automation_service()
            print(f"âœ… {result}")
            
        elif cmd == '2':
            result = system.stop_service()
            print(f"â¹ï¸ {result}")
            
        elif cmd == '3':
            status = system.get_system_status()
            print("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
            print(json.dumps(status, indent=2, ensure_ascii=False))
            
        elif cmd == '4':
            prompt = input("ğŸ“ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
            template = input("ğŸ“‹ í…œí”Œë¦¿ (product_detail/marketing): ") or "product_detail"
            style = input("ğŸ¨ ìŠ¤íƒ€ì¼ (clean/lifestyle/artistic): ") or "clean"
            
            task_id = system.generate_image_advanced(prompt, template, style)
            print(f"ğŸ¯ ì´ë¯¸ì§€ ìƒì„± ì‘ì—… ì‹œì‘: {task_id}")
            
        elif cmd == '5':
            prompts_input = input("ğŸ“ í”„ë¡¬í”„íŠ¸ë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”: ")
            prompts = [p.strip() for p in prompts_input.split(',') if p.strip()]
            
            if prompts:
                batch_id = system.batch_generate_images(prompts)
                print(f"ğŸ”„ ë°°ì¹˜ ìƒì„± ì‘ì—… ì‹œì‘: {batch_id} ({len(prompts)}ê°œ)")
            else:
                print("âŒ ìœ íš¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
        elif cmd == '7':
            task_id = input("ğŸ” ì‘ì—… IDë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
            status = system.get_task_status(task_id)
            print("ğŸ“‹ ì‘ì—… ìƒíƒœ:")
            print(json.dumps(status, indent=2, ensure_ascii=False))
            
        elif cmd == '0':
            print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤...")
            system.stop_service()
            return False
            
        else:
            print("âŒ ì˜ëª»ëœ ëª…ë ¹ì–´ì…ë‹ˆë‹¤.")
        
        return True
    
    # CLI ë©”ì¸ ë£¨í”„
    print_banner()
    
    while True:
        print_menu()
        command = input("\nğŸ¯ ëª…ë ¹ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš” (0-9): ").strip()
        
        if not handle_command(command):
            break
        
        input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        print("\n" + "="*60 + "\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê¶ê·¹ì˜ AI ì´ë¯¸ì§€ ìƒì„± ìë™í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    
    system = UltimateImageAutomationSystem()
    
    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = system.get_system_status()
    print("ğŸ“Š ì´ˆê¸°í™” ì™„ë£Œ!")
    print(json.dumps(status, indent=2, ensure_ascii=False))
    
    # CLI ëª¨ë“œ ì‹¤í–‰
    create_advanced_cli()


if __name__ == "__main__":
    main()